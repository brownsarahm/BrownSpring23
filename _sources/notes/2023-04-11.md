---
jupytext:
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.14.1
kernelspec:
  display_name: Python 3
  language: python
  name: python3
---

# Model Comparison

```{code-cell} ipython3
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import pandas as pd
from sklearn import datasets
from sklearn import cluster
from sklearn import svm
from sklearn import tree
# import the whole model selection module
from sklearn import model_selection
sns.set_theme(palette='colorblind')

# load and split the data
iris_X, iris_y = datasets.load_iris(return_X_y=True)
iris_X_train, iris_X_test, iris_y_train, iris_y_test = model_selection.train_test_split(
  iris_X,iris_y, test_size =.2)


# create dt,
dt = tree.DecisionTreeClassifier()

# set param grid 
params_dt = {'criterion':['gini','entropy'],
       'max_depth':[2,3,4,5,6],
    'min_samples_leaf':list(range(2,20,2))}
# create optimizer
dt_opt = model_selection.GridSearchCV(dt,params_dt,cv=10)


# optimize the dt parameters
dt_opt.fit(iris_X_train,iris_y_train)

# store the results in a dataframe
dt_df = pd.DataFrame(dt_opt.cv_results_)


# create svm, its parameter grid and optimizer
svm_clf = svm.SVC()
param_grid = {'kernel':['linear','rbf'], 'C':[.5, .75,1,2,5,7, 10]}
svm_opt = model_selection.GridSearchCV(svm_clf,param_grid,cv=10)

# optmize the svm put the CV results in a dataframe
svm_opt.fit(iris_X_train,iris_y_train)
sv_df = pd.DataFrame(svm_opt.cv_results_)
```

```{code-cell} ipython3
sv_df.head(1)
```

```{code-cell} ipython3
%matplotlib inline
```

```{code-cell} ipython3
svm_time = sv_df.melt(id_vars=['param_C', 'param_kernel', 'params',],
                      value_vars=['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time'])
sns.lmplot(data=sv_df, x='mean_fit_time',y='mean_test_score',
          hue='param_kernel',fit_reg=False)
```

```{code-cell} ipython3
svm_time.head()
```

```{code-cell} ipython3
sns.catplot(data= svm_time, x='param_kernel',y='value',hue='variable')
```

```{code-cell} ipython3
train_sizes, train_scores, test_scores, fit_times, score_times = model_selection.learning_curve(svm_opt.best_estimator_,iris_X_train, iris_y_train,
                              train_sizes= [.4,.5,.6,.8],return_times=True)
```

```{code-cell} ipython3
[train_sizes, train_scores, test_scores, fit_times, score_times]
```

```{code-cell} ipython3
train_scores.mean(axis=1)
```

```{code-cell} ipython3
[train_sizes, train_scores.mean(axis=1), test_scores.mean(axis=1),
                                fit_times.mean(axis=1), score_times.mean(axis=1)]
```

```{code-cell} ipython3
np.asarray([train_sizes, train_scores.mean(axis=1), test_scores.mean(axis=1),
                                fit_times.mean(axis=1), score_times.mean(axis=1)]).T
```

```{code-cell} ipython3
curve_df = pd.DataFrame(data = np.asarray([train_sizes, train_scores.mean(axis=1), test_scores.mean(axis=1),
                                fit_times.mean(axis=1), score_times.mean(axis=1)]).T,
                    columns = ['train_sizes', 'train_scores', 'test_scores', 'fit_times', 'score_times'])
```

```{code-cell} ipython3
curve_df.head()
```

```{code-cell} ipython3
curve_df_tall = curve_df.melt(id_vars='train_sizes',)
sns.relplot(data =curve_df_tall,x='train_sizes',y ='value',hue ='variable' )
```

```{code-cell} ipython3
def classification_confint(acc, n):
    '''
    Compute the 95% confidence interval for a classification problem.
      acc -- classification accuracy
      n   -- number of observations used to compute the accuracy
    Returns a tuple (lb,ub)
    '''
    interval = 1.96*np.sqrt(acc*(1-acc)/n)
    lb = max(0, acc - interval)
    ub = min(1.0, acc + interval)
    return (lb,ub)
```

```{code-cell} ipython3
svm_opt.best_score_, dt_opt.best_score_
```

- 150 samples
- 80% training size (20% test size)
- 10 fold cross validation

```{code-cell} ipython3
.1*.8*150
```

```{code-cell} ipython3
classification_confint(svm_opt.best_score_,12)
```

```{code-cell} ipython3
classification_confint(dt_opt.best_score_,12)
```

```{code-cell} ipython3
N_diff = 500
classification_confint(svm_opt.best_score_,N_diff), classification_confint(dt_opt.best_score_,N_diff)
```

```{code-cell} ipython3
svm_opt.best_estimator_.score(iris_X_test,iris_y_test), dt_opt.best_estimator_.score(iris_X_test,iris_y_test)
```

```{code-cell} ipython3
classification_confint(svm_opt.best_estimator_.score(iris_X_test,iris_y_test),12)
```

```{code-cell} ipython3
classification_confint(dt_opt.best_estimator_.score(iris_X_test,iris_y_test),12)
```

## MNIST Digits

```{code-cell} ipython3
digits_X, digits_y = datasets.load_digits(return_X_y=True)
```

```{code-cell} ipython3
digits_X.shape
```

```{code-cell} ipython3
svm_clf_digits = svm.SVC()
train_sizes, train_scores, test_scores, fit_times, score_times = model_selection.learning_curve(
                            svm_clf_digits,digits_X, digits_y,
                              train_sizes= [.4,.5,.6,.8,.9, .95],return_times=True)
```

```{code-cell} ipython3
digits_curve_df = pd.DataFrame(data = np.asarray([train_sizes, train_scores.mean(axis=1), test_scores.mean(axis=1),
                                fit_times.mean(axis=1), score_times.mean(axis=1)]).T,
                    columns = ['train_sizes', 'train_scores', 'test_scores', 'fit_times', 'score_times'])
```

```{code-cell} ipython3
digits_curve_df_tall = digits_curve_df.melt(id_vars = 'train_sizes', value_vars=[ 'train_scores', 'test_scores'])
sns.relplot(data =digits_curve_df_tall, x = 'train_sizes',y='value',hue='variable',)
```

```{code-cell} ipython3

```
